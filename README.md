# Beyond Associations: Reinforcement Learning for Sequential Market Basket Decisions
Clustered contextual bandits and tabular Q-learning with off-policy evaluation on real-world retail logs
Traditional market basket analysis (MBA) explains what tends to co-occur, but it does not decide what to do next. This paper advances from static rules to policy learning - we model shopping as a sequential decision problem and learn which product to recommend next to maximize business value (e.g., margin or revenue).
We build a practical pipeline that combines customer clustering (MiniBatchKMeans on profile features) with two reinforcement-learning approaches: a clustered contextual bandit (multinomial logistic per segment) and tabular Q-learning on states defined by (cluster, last category, day-of-week). Actions are product categories, and rewards are configurable (margin or revenue). Using retail-style data, the pipeline prepares transitions, trains the policies, and evaluates them under a consistent protocol.
To compare against classic methods, we implement two MBA baselines: first-order Markov (P(next|last)) and association-rule recommenders. All policies are assessed with off-policy evaluation (OPE) - SNIPS and Doubly Robust (DR) - with bootstrap confidence intervals to report uncertainty. We also include ablations (no-sequence, no-cluster) to show where gains come from and to avoid "too good to be true" results.
Compared with MBA, our approach optimizes an explicit business reward, personalizes by segment and context, reasons about sequences (long-term value), and supports counterfactual analysis via OPE - capabilities rule mining lacks. On the provided dataset, the codebase shows higher estimated reward for the RL policy (especially Q-learning) than both logging and MBA baselines under SNIPS/DR, while clustered bandits provide competitive, realistic gains. These results, together with ablations and intervals, indicate that moving from associations to policies is both theoretically sound and practically effective for basket-sequence recommendation.
